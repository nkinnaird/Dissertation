%!TEX root = ../thesis.tex

\thispagestyle{myheadings}

\graphicspath{{Body/Figures/Wa/Reconstruction/}{Body/Figures/Wa/Histogramming/}{Body/Figures/Wa/Pileup/}{Body/Figures/Wa/Pileup/TimeAndEnergySpectra/}{Body/Figures/Wa/Pileup/Scaling/}{Body/Figures/Wa/RatioAnalysis/}{Body/Figures/Wa/RatioAnalysis/MethodOverview/}{Body/Figures/Wa/RatioAnalysis/VW_Studies/}{Body/Figures/Wa/Datasets/Endgame/LostMuonFiles/MainCuts/}{Body/Figures/Wa/Datasets/ComparisonPlots/LostMuons/}{Body/Figures/Wa/Datasets/60h/SingleIteration/SingleFits/}{Body/Figures/Wa/Datasets/9d/EnergyThreshold/}{Body/Figures/Wa/Datasets/60h/NoTimeRand/}}

\chapter{\texorpdfstring{\wa}{wa} Measurement}
\label{chapter:wa}


The \gmtwo frequency \wa is measured by counting the number of detected positrons in the calorimeters above some energy threshold versus time, as described in \secref{section:WaIntro}. Doing so results in a histogram that is modulated by \wa, \figref{fig:gm2wiggle}. The \wa analysis consists of the steps needed to construct and fit the decay positron time spectrum and the necessary related systematic error studies.


\section{Reconstruction of decay positron hits}
\label{sec:ReconWest}


The calorimeters measure hit times and energies of incident particles, where these hit times and energies are determined by a reconstruction of the raw SiPM signals. In E989 there are two overall separate reconstruction algorithms, \texttt{ReconWest} and \texttt{ReconEast}, both written in the \textit{art} framework just as the tracking reconstruction. Each of these reconstruction algorithms is modularized, and the steps of the reconstruction process can be switched in and out at will. Using separate reconstruction methods instills confidence in any final results by removing single points of failure. The reconstruction method used in this analysis is \texttt{ReconWest}. A summary of its details will be presented here. A more thorough description is detailed by A. Fienberg \cite{AFThesis}.


The raw data are digitized waveforms, which are voltage traces from each SiPM for each calorimeter crystal. Due to the incredible amount of data coming at the high sampling rate, only those pulses which exceed some threshold are saved to disk. Traces are checked against this pre-configured threshold by passing all of the data through a GPU farm in real time \cite{Gohn:2016shi}. If any trace is found above threshold, then the data are saved from every SiPM in the hit calorimeter, for a time range around the over-threshold trace. This time range is called a time island, similar to that in the tracking reconstruction, and typically has a width of $\SI{40}{ns}$ \cite{AFThesis}.


The traces are fit with templates in order to extract the area and peak times of any present pulses. Each SiPM has its own templates, one for positrons and one for laser pulses. These templates are extracted from data, where each template is determined by collecting many single pulse traces from a SiPM, normalizing by pulse area, aligning in time, and averaging them. These templates were checked for many systematic effects in order to make sure that the constructed templates did not bias the energy or time measurements. These effects included hit angle, energy (pulse size), position, rate, and aging effects \cite{Kaspar:2016ofv,AFThesis}. To determine the time and energy of a hit, the SiPM trace is fit to it's corresponding templates using a \chisq minimization algorithm. In order to fit for multiple pulses in a single time island, the fitting procedure first fits with a single template, and then checks the residuals for any remaining peaks. If peaks above a threshold are found, then the fitting is repeated until all pulses have been fit. The algorithm's time measurements are unaffected by the number of pulses in a time island, and there is 100\% pileup separation at \ns{5}. See \figref{fig:TemplateFit} for a typical single template fit to a SiPM trace.


\begin{figure}
    \centering
    \includegraphics[width=0.6\textwidth]{TemplateFit}
    \caption[Template fit to SiPM trace]{A template fit in purple to a SiPM trace delineated by the black points which is in units of ADC counts \cite{AFThesis}.}
    \label{fig:TemplateFit}
\end{figure}


Once a pulse has been fit with a template, the pulse area needs to be converted to energy units using an energy calibration procedure. Several different techniques can be used, including a method that counts photo-statistics seen in the SiPMs. The default method is a comparison of lost muon energy signatures in the calorimeters. As described in \refref{lostmuonspaper}, muons lost from the storage ring can spiral inward and hit consecutive calorimeters with a specific time separation between calorimeter hits. These lost muons are minimum-ionizing particles, and thus leave a low energy signature in the crystals; see \secref{subsec:lostmuons}. Selecting on the time separation signature allows hits corresponding to lost muons to be isolated, and the peak of the energy signature can be used to determine the appropriate conversions from area to energy\footnote{Different channels can also be equalized based on the energy signatures.}. 


The energy calibration for positron hits as compared to lost muon hits then needs to be determined. Again there are several different techniques, including a comparison of endpoint energies for high energy positrons which tail off at the magic momentum of $\SI{3.094}{\GeV}$, and comparison with simulation. The default technique is to calibrate the energies such that the optimal energy threshold for the \wa analysis is near $\SI{1.7}{\GeV}$. Ultimately the accuracy of the energy calibration is relatively unimportant because it is not the energy units that really matter. Rather, the quantity of interest is the number of positrons above some energy threshold, where that threshold can be optimized empirically. Indeed the entire \wa analysis could be done only considering the area of the SiPM pulses as a proxy for the energy of the incident positrons.


Each pulse now has an associated energy and time. The measurement of \wa depends heavily on the time reconstruction since the analysis is a frequency extraction, thus the pulse times must be corrected for various effects in order to reach the precision goal. The fitted times for each pulse need to be aligned on a fill-by-fill basis relative to the injection time of the beam, corrected for any channel differences due to differing pulse shapes or optical fiber lengths, and corrected for any calorimeter time misalignments due to the use of different laser system components. The fill-by-fill alignment is corrected using the T0 detector as described in \secref{sec:T0}. The calorimeter channels are aligned in time using signals from islands with large simultaneous pulses in neighboring crystals. Calorimeters are time aligned using lost muon coincident events as described before. Once the times of the pulse fits or crystal hits have been determined, the energies can be corrected for gain effects measured by the laser system. As described in \secref{sub:LaserCalibrationSystem}, the laser calibration system corrects for out-of fill, STDP, and in-fill gain effects, in that order. \figref{fig:IFGFunction} shows an in-fill gain function fit to data for a single calorimeter crystal. Systematic effects from corrected gain variations are studied in \secref{sub:gainerror}.

\begin{figure}
    \centering
    \includegraphics[width=0.6\textwidth]{IFGFunction}
    \caption[In-fill gain function fit for a single calorimeter crystal]{In-fill gain function fit for a single calorimeter crystal (top) and fit residuals (bottom). Each crystal has its own in-fill and STDP gain function parameters. Plot courtesy of Matthias Smith.}
    \label{fig:IFGFunction}
\end{figure}



The last part of the calorimeter reconstruction is the clustering stage, which assembles individual crystal times and energies into the times, energies, and positions of decay positron impacts. For a time island with a single hit, the procedure is straightforward. The energy for the hit cluster is the sum of the individual hit crystal energies. The time for the cluster is taken as the time of the maximum energy hit in the island. This works because most of the deposited energy from a hit is localized to a single crystal. The position of the cluster is determined with a logarithmic weighting function between crystal hits, which for a $\SI{2}{\GeV}$ positron results in a resolution of $\SI{2}{mm}$ \cite{AFThesis}. \figref{fig:CaloCluster} shows a single calorimeter cluster from a positron hit in the calorimeter. For a time island with multiple hits, the individual crystal hits are separated in time, where the time partitioning separates hits that are $\SI{2.5}{ns}$ apart, and the clustering proceeds as before. For hits which are within this time window, a pileup event has occurred which is considered as a single hit. If the pileup event happens within the same crystal, then the multiple hits are measured as a single hit, and this needs to be corrected for using a pileup subtraction technique, as described in \secref{sub:pileupsubtraction}. For hits that occur in separate crystals, the pileup can be resolved using the spatial separation of the calorimeters. This is an ongoing area of work, and one technique is described in \refref{AFThesis}. For this analysis the spatial separation was disabled. This increases the amount of pileup seen in the data which for the precision of the Run~1 analysis result was found to be acceptable. 


\begin{figure}
    \centering
    \includegraphics[width=0.9\textwidth]{CaloCluster}
    \caption[Calorimeter cluster from SiPM traces fit with templates]{A single positron hit in the calorimeter, which resulted in a reconstructed calorimeter cluster \cite{AFThesis}. Each box is a crystal in the calorimeter, where the contained trace is the SiPM output fit with a template. The positron hit the crystal three crystals from the left and three crystals from the bottom, where it deposited most of its energy. Some of the energy was deposited in the neighboring crystals.}
    \label{fig:CaloCluster}
\end{figure}



\section{Construction of positron hit energy and time spectra}
\label{sec:Histogramming}


Once the reconstruction has processed all calorimeter hits into clusters, the energy and time spectra histograms are made. At the very last stage of the reconstruction procedure, an \textit{art} module takes the produced clusters and puts them into \ROOT \texttt{TTree} formats, where individual data members include the energies, times, calorimeter numbers, etc. of the individual clusters. There are of order 20,000--140,000 cluster data files per dataset, which are combined into order 200--1,400 \ROOT \texttt{TTree} files. These \ROOT \texttt{TTree}s are then passed through a \ROOT macro to produce \ROOT files with the histograms defined by the \texttt{TH1F} class, one \ROOT histogram file per tree file.


It should be noted that some of the parameter choices for the constructed histograms were informed by analysis results. All analysis parameters were identical between the distinct analyzed datasets, in order to simplify both the comparison and combination of different dataset results. This section describes the justification for the choice of histogram parameters. A table of the histogram parameters is shown in \tabref{tab:histogramparameters}.


\begin{table}
\centering
\setlength\tabcolsep{10pt}
\renewcommand{\arraystretch}{1.2}
\begin{tabular*}{.8\linewidth}{@{\extracolsep{\fill}}lc}
  \hline
    \multicolumn{2}{c}{\textbf{Time Spectra Parameters}} \\
  \hline\hline
    Parameter & Value \\
  \hline
    Energy threshold $(E_{th})$ & $\SI{1700}{\MeV}$ \\
    Bin width $(T_{c})$ & $\SI{149.2}{ns}$ \\
    Artificial dead time (ADT) & $\SI{5}{ns}$ \\
    Shadow dead time (SDT) & $\SI{5}{ns}$ \\
    Shadow gap time (SGT) & $\SI{10}{ns}$ \\
    Pileup energy scaling (C) & $1$ \\
    \gmtwo period $(T_{a})$ in Ratio Method & \mus{4.365411} \\
    Muon lifetime (\taumu) in Ratio Method & \mus{64.44} \\
  \hline 
\end{tabular*}
\caption[Parameters used in the construction of \wa time spectra]{Parameter values used in the construction of \wa time spectra.}
\label{tab:histogramparameters}
\end{table}


Energy and time histograms are made for each individual calorimeter. These are summed together to form histograms of all hit times and energies. \figref{fig:energyHist} shows a sample energy spectrum for the Endgame dataset. An energy threshold is applied to the clusters before filling the time histograms. As described at the end of \secref{section:WaIntro}, the optimal energy threshold is where the quantity $NA^{2}$ reaches the maximum, at least in the case of a five parameter fit\footnote{Using the final fit function and looking at the error directly on the fitted \wa frequency, a slightly better estimate can be found.}. By scanning over energy threshold and fitting the resulting time spectra with \equref{eq:5parfunc}, the optimal energy threshold can be determined. The optimal choice of energy threshold was determined to be $\SI{1700}{\MeV}$, in accordance with the cluster reconstruction energy calibration; see \figref{fig:OptimalEnergyThreshold}. 

\begin{figure}
    \centering
    \includegraphics[width=0.7\textwidth]{basicEnergyHist}
    \caption[Sample energy spectrum]{Energy spectrum for hits with cluster times greater than \mus{25} in all calorimeters on a linear scale. The peak at about 170 \MeV corresponds to lost muons layed on top of the low energy decay positron part of the spectrum. Data are from the Endgame dataset.}
    \label{fig:energyHist}
\end{figure}


\begin{figure}
\centering
    \begin{subfigure}[t]{0.45\textwidth}
        \centering
        \includegraphics[width=\textwidth]{FiveParameter_N_0_Vs_ETh_9d}
        % \caption{}
    \end{subfigure}
     \begin{subfigure}[t]{0.45\textwidth}
        \centering
        \includegraphics[width=\textwidth]{FiveParameter_A_Vs_ETh_9d}
        % \caption{}
    \end{subfigure}
       
    \begin{subfigure}[t]{0.45\textwidth}
        \centering
        \includegraphics[width=\textwidth]{FiveParameter_NAsq_Vs_ETh_9d}
        % \caption{}
    \end{subfigure}
    \begin{subfigure}[t]{0.45\textwidth}
        \centering
        \includegraphics[width=\textwidth]{FullRatio_sigmaR_Vs_ETh_9d}
        % \caption{}
    \end{subfigure}% 
\caption[Determination of optimal energy threshold]{The optimal energy threshold can be determined from the $NA^{2}$ quantity as described in \secref{section:WaIntro} from five parameter fits to the data (bottom-left) or from the calculated error with the final fit function (bottom-right). Fitted $N$ and $A$ parameters are also shown (top) which satisfy Equations~\ref{eq:Nth} and \ref{eq:Ath}. The maximum $NA^{2}$ and minimum $\sigma_{R}$ are determined using seven parameter polynomial fits to the respective quantities. The optimal threshold varies slightly per calorimeter and per dataset. Since the region of the minimum is relatively flat, a single energy threshold of 1700 \MeV was chosen. Data are from the 9d dataset.}
\label{fig:OptimalEnergyThreshold}
\end{figure}



The optimal bin width for the time histograms was determined to be $\SI{149.2}{ns}$, the peak of the cyclotron period distribution determined from the fast rotation analysis of the data\footnote{A change in the bin width of order \ns{0.1} has very little effect on the extracted \wa frequency as seen in \secref{sub:binning_systematic_errors}.}. As described in \secref{sub:beam_debunching}, this bin width combined with a time randomization on each cluster over a range of $\pm T_{c}/2 = \SI{149.2}{ns} / 2$ serves to eliminate the fast rotation signal in the data\footnote{An alternative approach is to randomize all times in a single fill by half the cyclotron period as opposed to each individual pulse.}. This randomization is done using \ROOT's \texttt{TRandom3} class. As will be described in \secref{sub:vw_term}, the cluster times are also randomized by half the vertical waist period, $\pm T_{VW}/2$, \equref{eq:VWfreq}. Putting the frequency in terms of the field index $n$ and the cyclotron frequency $f_{c}$ the VW period is given by
    \begin{align}
        T_{VW} = \frac{1}{f_{VW}} = \frac{1}{(1-2\sqrt{n}) \cdot f_{c}}.
    \end{align}
This randomization is done in order to remove the effects of the VW in the data\footnote{Even though the VW frequency was found to be changing over the course of the fill, the change is small enough such that this constant time randomization was found to remove all residual traces of the VW in the data.}. The default random seed for each histogram \ROOT file is the hash of the unique input file name using C++'s standard hash class. Other random seeds can be chosen in order to verify the consistency of fit results. Histograms are defined with a time range of 0--\mus{699.8972} (the integer multiple of the bin width closest to \mus{700}), corresponding to 4691 bins. 

% Clusters with times less than \mus{25} or greater than \mus{660} are dropped, corresponding to 4256 bins containing data.



\subsection{Pileup subtraction}
\label{sub:pileupsubtraction}


As described in \secref{sec:Calorimeters}, there will be a certain amount of pileup in the detectors. Pileup distorts the measured energy and time spectra in a time-dependent way which is dangerous for the \wa measurement. For the time histogram of clusters above energy threshold, the number of counts will be wrong for cases where two below-threshold particles are registered as a single cluster above threshold, and where two above-energy threshold particles are registered as a single cluster. In the former, an extra count is added into the histogram, and in the latter a count is missed. The case where two lower energy positrons are registered as a single, higher energy cluster will have a different \gmtwo phase than an actual single cluster at the same energy. This is because the lower energy positrons on average originate from muons which have traveled further around the ring, due to acceptance effects. These muons which have traveled further around the ring have spent more time in the magnetic field, and thus their spins have precessed more. See \figref{fig:PileupExample}. Clusters which originate from pileup events therefore have a different \gmtwo phase than non-pileup events. 


If pileup was a constant effect in time, then the phase of the time histogram would be shifted by some constant amount, and the \wa frequency extracted would be unaffected. However, the rate of pileup in the detectors changes over the time of a fill, as muons decay. The rate of pileup varies with the square of the instantaneous rate of positrons striking the calorimeters; double pileup events, which consist of events where two hits are registered as a single cluster, have a lifetime approximately half that of single hit events, and similarly for higher orders of the pileup effect\footnote{The true pileup spectrum is technically the convolution of the single hit time spectrum with itself, including effects from the non-linear dead time of the detectors.}. Because the rate of hits in the detectors oscillates at the \gmtwo frequency, pileup will increase and decrease accordingly leading to oscillations in the pileup time spectra at \wa and 2\wa. This time-dependent distortion means that the pileup effect needs to be included in the fit function or subtracted out of the data in order to extract the correct \wa frequency. The former is challenging due to the non-linear nature of the dead time of the detectors, and would include another phase in the argument of the cosine term in the fit function, thus worsening the statistical precision of the extracted \wa frequency. All analyzers thus construct an approximate pileup spectrum and subtract it from the data before fitting.

% The lifetime of double pileup events in the detectors, where the word double indicates cases where two hits are registered as a single cluster, will go approximately as half the lifetime of single hit events\footnote{It is not exactly half when including the non-linear dead time of the detectors}, and similarly for triple and higher orders of the pileup effect. 


% -need to mention the \% level effect of pileup - ~1\% but where do you get that number...


\begin{figure}
    \centering
    \includegraphics[width=0.5\textwidth]{PileupExample}
    \caption[Pileup example]{Pileup example, where two low energy positrons are registered as a single high energy positron. The black arrows indicate the (exaggerated) direction of the muon spins at the time of decay. Because of acceptance effects the lower energy decay positrons typically come from muons which have traveled further around the ring, and thus the muon spins have precessed more in the magnetic field, leading to a different measured \gmtwo phase for pileup events.}
    \label{fig:PileupExample}
\end{figure}


There are various methods to construct the pileup spectra which are subtracted from the main time and energy spectra. The method used in this analysis is called the `asymmetric shadow method', used successfully in E821 \cite{E821PileupShadow}. This method statistically constructs an approximation of the pileup spectrum from the data by assuming that the probability of observing a pileup pulse is the same as the probability that two pulses will be offset by some small amount of time, such as \ns{10}. The method works by looking in time windows after trigger pulses to see if a `shadow' pulse exists. If such a pulse exists, then a shadow doublet is created, see \figref{fig:ShadowPileupMethod}. The pileup spectrum $P$ is then the sum of the shadow doublets minus the singlets used in their construction, $P = D - S$. The width of the time window, and the time offset from the trigger pulse to the window, are called the shadow dead time (SDT) and shadow gap time (SGT) respectively. The times and energies of the constructed pileup doublets are taken as
            \begin{gather}
                E_{\text{doublet}} = C \cdot (E_{1} + E_{2}), \label{eq:Edoublet} \\
                t_{\text{doublet}} = \frac{t_{1} \cdot E_{1} + (t_{2}-SGT) \cdot E_{2}}{E_{1} + E_{2}}, \label{eq:tdoublet}
            \end{gather}
where the energy of the doublet is the sum of the two singlet pulses $E_{1,2}$ times some calibration constant $C$, with a default value of 1, and the time of the doublet is the energy-weighted time of the two singlets $t_{1,2}$. The procedure for constructing the pileup spectra is as follows:
\begin{itemize}
    \item{Put each hit into a vector corresponding to a specific fill and a specific calorimeter}
    \item{Time order the hits}
    \item{Loop through the hits; for each hit look within a window of width SDT a time SGT later to see if a shadow pulse exists}
    \item{If a shadow pulse exists, construct a shadow doublet with energies and times as defined in Equations~\ref{eq:Edoublet} and \ref{eq:tdoublet}}
    \item{Randomize $t_{\text{doublet}}$ over the range $\pm T_{c}/2$ (to remove fast rotation as before, \secref{sub:beam_debunching})}
    \item{Per calorimeter, construct pileup energy and time spectra as $P = D - S$, where $D$ is the sum of doublets and $S$ is the sum of singlets used in the construction of the doublets, with the times of the singlets set as $t_{\text{doublet}}$; when constructing the pileup time spectra, only include those doublets and singlets above the energy threshold}
\end{itemize}
Thus pileup energy and time spectra are constructed for each calorimeter, which can then be subtracted off the calorimeter cluster energy and time histograms. When combining the calorimeter data, the individual pileup histograms are added together before subtracting them from the calorimeter sum histograms.


\begin{figure}
    \centering
    \includegraphics[width=\textwidth]{ShadowPileupMethod}
    \caption[Shadow pileup method]{The shadow pileup method looks for shadow clusters within a time window SDT, a small time away (SGT) from trigger clusters. If a shadow cluster is found, an artificial doublet is formed and included in the pileup spectra if it exceeds the chosen energy threshold. \textbf{potentially long way from text reference}}
    \label{fig:ShadowPileupMethod}
\end{figure}


In order to produce an estimate of the pileup spectra which best matches the data, an artificial dead time (ADT) is applied to the data before time randomization. This is done because the true dead time of the detectors depends on the energies and spatial separation of the incoming hits. While this slightly increases pileup, by applying an artificial deadtime and matching the shadow window time, the pileup estimation is improved and the overall systematic error is reduced. The construction of the artificial pileup is handled in the same way as the construction of the shadow pileup, with SGT set to \ns{0}. The constructed artificial doublets replace the singlets in the data. The value for the ADT and SDT is set at \ns{5}, the time threshold at which pileup is 100\% resolved. 

The value of the SGT is simply set to twice the SDT, in order to push the shadow window out to times well beyond the dead time of any pileup events, but not so far that an appreciable fraction of muons have decayed. The value of the doublet energy scaling factor C is set to 1, which is a fine approximation as the spatial separation in the reconstruction is turned off\footnote{With the spatial separation turned off, `pileup' events can occur in crystals that are easily separated by eye. While this increases the level of pileup seen in the data, the pileup approximation method also does not consider the spatial separation, and thus handles the level of pileup accordingly.}. The values for each pileup parameter were shown previously in \tabref{tab:histogramparameters}. See \secref{sub:pileuperror} for systematic studies on the effect on \wa due to these chosen parameters.


The pileup energy spectrum and the cluster energy spectrum are shown in \figref{fig:ClusterEnergiesVsPileupEnergies}. In general, the two lobes starting at approximately $\SI{3}{\GeV}$ and $\SI{6}{\GeV}$ consist of double and triple pileup events respectively\footnote{All orders of pileup fill out the whole energy range, but certain regions consist of mostly one order.}. It can be seen that the shadow method of pileup construction produces a pileup energy spectra which is a good approximation of the cluster energies above the end point of a single decay positron, for cases of double and even triple pileup. The shape difference arises from two factors. First, the shadow method is only written to construct doublets, and does not consider cases of triple or higher orders of pileup. Second, the real pileup in the data contaminates the construction of the shadow pileup spectra, such that a shadow doublet can be constructed from real pileup pulses. While this alleviates the triplet problem slightly, it means that the doublet pileup spectrum is slightly wrong. The corrected energy spectra (cluster energies minus pileup energies), can be seen in \figref{fig:AddedEnergies}. The shape mismatch is even more apparent as the corrected energy spectrum is high for energies above the expected tail of the true energy distribution, and then goes negative before tailing off to zero. 


    \begin{figure}
        \centering
        \includegraphics[width=\textwidth]{ClusterEnergiesVsPileupEnergies}
        \caption[Cluster energies vs pileup energies]{Cluster energies in black are plotted vs pileup energies in red, for all calorimeters added together, plotted on a log scale. At energies below about 2.4 GeV the pileup energy spectrum goes negative. In this plot the absolute value of the pileup energies is plotted, and a spike at about 2.4 GeV can be seen as a consequence of this. The shapes do not match perfectly for the constructed pileup spectra, which can be seen at high energies. Data are from the 60h dataset.}    
        \label{fig:ClusterEnergiesVsPileupEnergies}
    \end{figure}

% It should be noted that for energies above $\SI{3.094}{\GeV}$ there is still a shape mis-match even though the red and black curves overlap due to the plotting scale. 

    \begin{figure}
    \centering
        \begin{subfigure}[]{0.45\textwidth}
            \centering
            \includegraphics[width=\textwidth]{AddedEnergies}
            \caption{Log scale - the corrected energy spectrum goes negative around 5 GeV.}
        \end{subfigure}% %you need this % here to add spacing between subfigures
        \hspace{1cm}
        \begin{subfigure}[]{0.45\textwidth}
            \centering
            \includegraphics[width=\textwidth]{AddedEnergiesZoomed}
            \caption{Linear scale - zoomed in to show the shape.}
        \end{subfigure}
    \caption[Non-corrected and pileup corrected cluster energies]{Plots for the pre-corrected and corrected energy spectra are shown, all calorimeters added together. Because the triplets and contamination are not accounted for, the corrected energy spectrum does not lie exactly along zero above the energy response of the detectors. Data are from the 60h dataset.}
    \label{fig:AddedEnergies}
    \end{figure}



In order to produce a slightly better estimate of the pileup, a multiplier can be applied to the pileup energy and time spectra. By taking the ratio of cluster energies over pileup energies and fitting the region where the energies are dominated by real pileup doublets, a correction factor of approximately 3-4\% is found, as shown in \figref{fig:EnergyRatio}. The default multipliers for the Run~1 datasets are 1.03210, 1.03413, 1.03387, and 1.03819 for the 60h, HighKick, 9d, and Endgame datasets respectively. Similarly, the cluster times can be examined for cluster energies over \SI{3500}{\MeV}, where the clusters consist purely of pileup pulses, \figref{fig:PileupTimesRatio}. By taking the ratio of the pileup corrected times over all times, the level of residual pileup can be determined. Just as in the ratio of the energies, an approximate 3-4\% factor is found. When applying this multiplier, the cluster times above \SI{3.5}{\GeV} can be seen to be eliminated as in \figref{fig:PileupTimesRatio}. As will be shown in \secref{sub:pileuperror}, the scale of this multiplier is well within $1\sigma$ of the pileup multiplier error. The final pileup time spectrum for those pileup pulses above energy threshold is shown in \figref{fig:PileupTimeSpectrum}. 


    \begin{figure}
        \centering
        \includegraphics[width=.5\textwidth]{EnergyRatio}
        \caption[Cluster energies divided by pileup energies]{Cluster energies divided by pileup energies. A region from \SI{3500}{}--\SI{4500}{\MeV} is fit to a straight line, where the doublets dominate the energy distribution. Data are from the 9d dataset.}
        \label{fig:EnergyRatio}
    \end{figure}


    \begin{figure}
    \centering
        \begin{subfigure}[]{0.45\textwidth}
            \centering
            \includegraphics[width=\textwidth]{PileupSubtractedTimesComparison-NoAutoScaling}
            % \caption{Cluster t}
        \end{subfigure}% %you need this % here to add spacing between subfigures
        \hspace{1cm}
        \begin{subfigure}[]{0.45\textwidth}
            \centering
            \includegraphics[width=\textwidth]{PileupSubtractedTimesRatio-NoAutoScaling}
            % \caption{}
        \end{subfigure}

        \begin{subfigure}[]{0.45\textwidth}
            \centering
            \includegraphics[width=\textwidth]{PileupSubtractedTimesComparison-AutoScaling}
            % \caption{}
        \end{subfigure}% %you need this % here to add spacing between subfigures
        \hspace{1cm}
        \begin{subfigure}[]{0.45\textwidth}
            \centering
            \includegraphics[width=\textwidth]{PileupSubtractedTimesRatio-AutoScaling}
            % \caption{}
        % \label{fig:correctedclustertimes}
        \end{subfigure}
    \caption[Cluster times above \SI{3.5}{\GeV}]{Cluster times and pileup corrected times for counts above \SI{3.5}{\GeV} (left) and their ratio (right). The top two plots are used to determine the approximate level of residual pileup left in the data, coming out to about 3\%. The bottom two plots show the application of that factor and the resulting removal of the remaining pileup. Data are from the 9d dataset.}
    \label{fig:PileupTimesRatio}
    \end{figure}



    \begin{figure}
        \centering
        \includegraphics[width=0.6\textwidth]{PileupTimeSpectrum}
        \caption[Pileup time spectrum above threshold]{Plotted is the constructed pileup time spectrum on a log scale. Oscillations at \wa can be seen by eye. The histogram is fit to a simple two parameter exponential to get an idea of the lifetime of the pileup, calculated here as $\SI{31.95}{\micro s}$, which as expected is close to half of the muon lifetime at about $\SI{64.44}{\micro s}$. Data are from the 60h dataset. \textbf{potentially long way from text reference}}
        \label{fig:PileupTimeSpectrum}
    \end{figure}





It has been determined that regardless of any residual shape mismatch in the cluster times below \SI{3.5}{\GeV}, the systematic error on the extracted \wa frequency due to the pileup is within the target uncertainty for the level of statistics in the Run~1 dataset, \secref{sub:pileuperror}. For analyses after Run~1 where the error budget is reduced, it may be necessary to improve the shadow method to account for triplets and the contamination. Finally, since the pileup is statistically constructed and then subtracted from the data, the errors on the final time histogram are no longer pure Poissonian. The proper calculation of the errors is detailed in \appref{app:PileupErrors}.


% https://gm2-docdb.fnal.gov/cgi-bin/private/RetrieveFile?docid=13963&filename=PileupScaleShadowTesting.pdf&version=1
% https://gm2-docdb.fnal.gov/cgi-bin/private/RetrieveFile?docid=14394&filename=PileupFormEtc.pdf&version=2

\clearpage

\subsection{Ratio Method}
\label{sub:ratio_method}

% I put this here because technically the ratio method involves modifying the actual data that is being fit

The method used in this analysis to extract \wa is called the ``Ratio Method,'' or sometimes ``R-Method.'' It is a technique that modifies the data in such a way that the exponential decay in the time histogram is removed, and slowly varying effects are reduced. It was used successfully in the E821 experiment \cite{JKThesis,LDThesis,JPThesis}. A full derivation of the equations in the method is given in \appref{app:RatioDerivation}; here is given a short summary. \figref{fig:RatioFormationFunctions} provides a pictorial representation of how the method works.

The method works by randomly dividing the data into four separate datasets, one with the times of all clusters shifted up by half a \gmtwo period, $+$\Tatwo, one with cluster times shifted down by half a \gmtwo period, $-$\Tatwo, and two unchanged. Assuming the data are described by the five parameter function described in \secref{section:WaIntro} and shown in \figref{fig:fiveparamfunc}, %\equref{eq:5parfunc}
        \begin{align} \label{eq:5parfuncrepeated}
            N_{d}(t, E_{th}) = N_{0}(E_{th}) \cdot e^{-t/\gamma\tau_{\mu}} \cdot [1 + A(E_{th}) \cos(\omega_{a}t+\phi(E_{th}))],
        \end{align}
and that the data are equally split into four subsets, then the four new datasets are given as\footnote{When handling the pileup in the ratio method, the pileup time spectra are split into four datasets and time-shifted in the same way as the cluster hit times. Associated doublets and singlets are kept together in the same individual dataset, and the four pileup datasets are subtracted from their respective ratio datasets before forming the ratio.}:
    \begin{equation}
    \begin{aligned}
        u_{+}(t) &= \frac{1}{4} N_{5}(t+T/2) \\
        u_{-}(t) &= \frac{1}{4} N_{5}(t-T/2) \\
        v_{1}(t) &= \frac{1}{4} N_{5}(t) \\
        v_{2}(t) &= \frac{1}{4} N_{5}(t)
    \end{aligned}
    \end{equation}
In order to time shift the data as such, \Ta needs to be known a priori to reasonable precision. The value used is taken from the E821 result, and its value is taken as $1/f_{a}$, where $f_{a}$ is \SI{0.2290735}{MHz}:
        \begin{align}
            T_{a} \approx \SI{4.365411}{\micro s}
        \label{eq:Ta}
        \end{align}
This value for $f_{a}$ was determined by averaging column 2 of Table XV of the E821 Final Report \cite{E821FinalReport}, which consists of the $f_{a}$ results for the different run periods in that experiment. A systematic error on the choice of this parameter is calculated in \secref{sub:TimeShiftingParameters} and is negligible for the precision known.


The datasets are then combined as 
    \begin{equation}
    \begin{aligned}
        U(t) &= u_{+}(t) + u_{-}(t), \\
        V(t) &= v_{1}(t) + v_{2}(t),
    \label{eq:UandV}
    \end{aligned}
    \end{equation}
both of which are shown in \figref{fig:UVfuncs}. It is immediately apparent that the $U(t)$ data are shifted 180\textdegree{} out of phase from the $V(t)$ data. The ratio is then defined as\footnote{The ratio can also be defined with $U(t) - V(t)$ in the numerator, however then the phase of the ratio spectrum is shifted 180\textdegree{} from the original $N_{5}(t)$ spectrum.}
    \begin{align}
        R(t) &= \frac{V(t) - U(t)}{V(t) + U(t)}
    \label{eq:ratioUV}
    \end{align}
where the numerator and denominator are plotted in Figures~\ref{fig:rationumfunc} and \ref{fig:ratiodenomfunc} respectively. The numerator is an exponentially decaying cosine, while the denominator is a simple exponential, both of which can be seen as originating from the difference and sum of the $U(t)$ and $V(t)$ data respectively. The resulting ratio spectrum can be seen in \figref{fig:ratiofunc}, where the exponential has been eliminated. The fit function is then reduced from five parameters down to three:
    \begin{align}
        R(t) \approx A \cos(\omega_{a}t) - C,
    \label{eq:ratiowithC}
    \end{align}
where  
    \begin{align}
        C = \frac{1}{16} \Big(\frac{T}{\tau}\Big)^{2} \approx 2.87 * 10^{-4},
    \end{align}
and these functions have been determined from the time-shifted five parameter function plugged into the $U(t)$ and $V(t)$ variables. In addition to the exponential being eliminated, any slow terms in the data get time-shifted and divided as well, such that the amplitude of said slow effects are reduced. For faster effects, the degree of cancellation of the effect is dependent on the frequency. Effects at frequencies which are an odd multiple of \wa are preserved while effects at an even multiple of \wa are completely canceled out. An example is shown in \figref{fig:CancellationInRatioMethod}. While this makes fitting the data easier in some cases, in others it is a downside that effects which still need to be included in the fit function now have their amplitudes reduced, making them harder to fit.


    \begin{figure}
    \centering
        \begin{subfigure}[t]{0.45\textwidth}
            \centering
            \includegraphics[width=\textwidth]{FiveParamFunc}
            \caption{The five parameter function defined in \equref{eq:5parfuncrepeated}, which describes the incoming data to first order.}
        \label{fig:fiveparamfunc}
        \end{subfigure}%

        \vspace{2mm}
        \begin{subfigure}[t]{0.45\textwidth}
            \centering
            \includegraphics[width=\textwidth]{UVFuncs}
            \caption{$U(t)$ and $V(t)$ functions which describe the time-shifted and un-shifted ratio datasets.}
        \label{fig:UVfuncs}
        \end{subfigure}
        \hspace{5mm}
        \begin{subfigure}[t]{0.45\textwidth}
            \centering
            \includegraphics[width=\textwidth]{RatioNumFunc}
            \caption{The numerator function in the formed ratio, $V(t) - U(t)$. It is an exponentially decaying cosine.}
        \label{fig:rationumfunc}
        \end{subfigure}%
        \vspace{2mm}
        \begin{subfigure}[t]{0.45\textwidth}
            \centering
            \includegraphics[width=\textwidth]{RatioDenomFunc}
            \caption{The denominator function in the formed ratio, $V(t) + U(t)$. It is a decaying exponential.}
        \label{fig:ratiodenomfunc}
        \end{subfigure}
        \hspace{5mm}
        \begin{subfigure}[t]{0.45\textwidth}
            \centering
            \includegraphics[width=\textwidth]{RatioFunc}
            \caption{The ratio function, which describes the data after it has been handled according to the text. To first order it is a simple cosine.}
        \label{fig:ratiofunc}
        \end{subfigure}% 
    \caption[Ratio formation functions]{Functions describing the formation of the ratio data. \textbf{potentially long way from text reference}}
    \label{fig:RatioFormationFunctions}
    \end{figure}


    \begin{figure}
        \centering
        \includegraphics[width=.6\textwidth]{Fitted_Avw_Vs_Wvw_1x-10x}
        \caption[Cancellation of effect in Ratio Method versus frequency]{Fitted amplitude for a VW effect as a function of frequency in units of \wa in a Toy MC simulation, with a five parameter function in red and a three parameter ratio function in black. The input amplitude is 0.05. The fall off of red points is due to the high frequencies relative to the bin widths leading to an underestimate of the amplitude; performing an integral fit removes this trend. As shown, the amplitude of the effect goes to zero for frequencies which are an even multiple of \wa.}
        \label{fig:CancellationInRatioMethod}
    \end{figure}



 In order to eliminate the constant $C$ at the end of \equref{eq:ratiowithC}, a different weighting scheme is used in this analysis as described in \refref{statisticspaper}:
    \begin{equation}
    \begin{aligned}
        u_{+}(t) &= \frac{e^{T/2\tau}}{2 + e^{T/2\tau} + e^{-T/2\tau}} N_{5}(t+T/2) \\
        u_{-}(t) &= \frac{e^{-T/2\tau}}{2 + e^{T/2\tau} + e^{-T/2\tau}} N_{5}(t-T/2) \\
        v_{1}(t) &= \frac{1}{2 + e^{T/2\tau} + e^{-T/2\tau}} N_{5}(t) \\
        v_{2}(t) &= \frac{1}{2 + e^{T/2\tau} + e^{-T/2\tau}} N_{5}(t)
    \label{eqn:fourHistsInText}
    \end{aligned}
    \end{equation}
Here $\tau = \tau_{\mu}$ where $\tau_{\mu}$ is the time-dilated muon lifetime, and the factors out front are each close to $1/4$ and account for the degree of muon decay over a time period of \Tatwo. Similar to \Ta, the muon lifetime must be known a priori. Its value is taken as \mus{64.44}, determined from fits to the data. A systematic study regarding this parameter is described in \secref{sub:TimeShiftingParameters}. The ratio spectrum is then almost exactly described by just the cosine term,
    \begin{align} \label{eq:threeparamratio}
        R(t) \approx A \cos(\omega_{a}t),
    \end{align}
in the absence of other effects in the data. 




\section{Fitting the data}
\label{sec:Fitting}


The basic five parameter function used to the fit the data as described before is given as\footnote{In the current section the actual fit parameters are in bold.}
    \begin{align}
        f(t) = \boldsymbol{N_{0}} \cdot e^{-t/\boldsymbol{\tau}} \cdot (1 + \boldsymbol{A} \cdot \cos(\omega_{a}t + \boldsymbol{\phi})),
    \label{eq:fiveparfuncagain}
    \end{align}
where the fit parameter for \wa is recast in terms of a ppm level shift $\boldsymbol{R}$ on a reference frequency,
    \begin{align}
        \omega_{a} = 2 \pi \cdot \SI{0.2291}{MHz} \cdot (1 + \boldsymbol{R} \times 10^{-6}).
    \label{eq:wablind}
    \end{align}
This reference frequency of $\SI{0.2291}{MHz}$ was the same reference frequency used in E821, and $\boldsymbol{R}$ is blinded at the hardware and software levels \cite{ClockManual,SoftwareBlinding}. Fitting the data with \equref{eq:fiveparfuncagain} however is insufficient to properly describe the data. An FFT of the residuals between fit and data is shown in \figref{fig:FFT_fiveParameter}. There are peaks due to beam dynamics frequencies corresponding to the CBO, VW, and some beat frequencies with \wa. In order to properly account for these effects, additional terms need to be added to the fit function. 


\begin{figure}
    \centering
    \includegraphics[width=.8\textwidth]{FFT_fiveParameter_60h_noTimeRand}
    \caption[FFT of five parameter fit residuals]{FFT of five parameter fit residuals from the 60h dataset. Peaks corresponding to beam dynamics frequencies of the CBO and VW and some beat frequencies with \wa are readily apparent. A rise at low frequencies corresponds to the effects of the lost muons in the data. The VW peak diminishes with application of the cyclotron period time randomization and disappears entirely with the VW period time randomization.}
    \label{fig:FFT_fiveParameter}
\end{figure}


\equref{eq:fiveparfuncagain} can be expanded to 
    \begin{align}
        f(t) = \Lambda(t) \cdot V(t) \cdot N_{cbo}(t) \cdot \boldsymbol{N_{0}} \cdot e^{-t/\boldsymbol{\tau}} \cdot (1 + A_{cbo}(t) \cdot \cos(\omega_{a}t + \phi_{cbo}(t))),
    \label{eq:TmethodFunction}
    \end{align}
where many additional terms have been added in order to account for effects in the data. The various additional terms $\{N_{cbo}(t), A_{cbo}(t), \phi_{cbo}(t), V(t), \Lambda(t)\}$ are described in the following sections. Fitting the data with this function, referred to as the ``Threshold Method'' or just ``T-Method,'' while not the subject of this dissertation, was done in this analysis as a diagnostic and informative tool for the Ratio Method analysis. 


In order to fit the ratio time spectra as constructed in \secref{sub:ratio_method}, a different function is used. While the immediate inclination would be to use an expansion of \equref{eq:threeparamratio} with additional effects included similar to the T-Method fit function, instead the fit function used is a return to the explicit definition of the construction of the ratio time spectra in Equations~\ref{eq:UandV} and \ref{eq:ratioUV}. Including the additional effects previously mentioned, the fit function becomes
    \begin{gather}
        R(t) = \frac{2f(t) - f_{+}(t) - f_{-}(t)}{2f(t) + f_{+}(t) + f_{-}(t)}, \\
        f_{\pm}(t) = f(t \pm T_{a}/2), \\
        f(t) = \Lambda(t) \cdot V(t) \cdot N_{cbo}(t) \cdot (1 + A_{cbo}(t) \cdot \cos(\omega_{a}t + \phi_{cbo}(t))).
    \label{eq:fullratiofunction}
    \end{gather}
The $f(t)$ given here differs from that in \equref{eq:TmethodFunction} in that the $\boldsymbol{N_{0}} \cdot e^{-t/\boldsymbol{\tau}}$ terms have divided out, thus reducing the number of fit parameters necessary to model the data. Using this function as opposed to an expansion of the three parameter ratio function eliminates any approximations made in that three parameter function derivation, and any fit parameters should be consistent in value between the T-Method and Ratio Method results, barring adjustments due to the application of the Ratio Method. 

Because the Ratio Method reduces the sensitivity of the \wa determination to various effects in the data, peaks that appear in the FFT of the five parameter fit residuals do not appear in the FFT of the three parameter ratio fit residuals, \figref{fig:fft_threeParamRatio}. Indeed unless one looks at the FFT over the early part of the fit (first \mus{30}) or at the shape of the Ratio Method denominator, one might not know the effects even exist in the data at all, barring occasionally poor \chisq's. Nevertheless, those effects typically still need to be included in the fit function for a proper estimation of \wa. Because of the reduction in sensitivity in the ratio fits, there are some parameters which the ratio has trouble fitting by itself. Using the results from a T-Method fit to the data can then be a useful tool for constraining those specific parameters.


\begin{figure}
\centering
    \begin{subfigure}[t]{0.67\textwidth}
        \centering
        \includegraphics[width=\textwidth]{FFT_threeParRatio_60h}
        \caption{FFT of fit residuals over all times within the fit range. There is no immediately apparent structure for residual effects left out of the fit function.}
    \end{subfigure}%

    \begin{subfigure}[t]{0.67\textwidth}
        \centering
        \includegraphics[width=\textwidth]{FFT_threeParRatio_earlyTimes_60h}
        \caption{FFT of fit residuals over the first \mus{30}. The CBO peak can be seen above the noise, though the corresponding beat frequencies do not appear.}
    \end{subfigure}
\caption[FFT of three parameter ratio fit residuals]{FFT of three parameter ratio fit residuals of the 60h dataset. Dashed blue lines indicate various beam dynamics frequencies and their beat frequencies with \wa.}
\label{fig:fft_threeParamRatio}
\end{figure}




\subsection{CBO terms}
\label{sub:cboterms}


As described in \secref{sub:CBO}, the CBO effect modulates the \wa oscillation. This shows up as a modification on the five parameter function parameters $\{N_{0}, A, \phi\} \rightarrow \{N_{0} \cdot N_{cbo}(t), A_{cbo}(t), \phi_{cbo}(t)\}$ where these terms are given to first order as
    \begin{align}
        N_{cbo}(t) &= (1 + \boldsymbol{A_{cbo-N}} \cdot e^{-t/\boldsymbol{\tau_{cbo}}} \cdot \cos(\omega_{cbo}(t) \cdot t + \boldsymbol{\phi_{cbo-N}})) \label{eq:Ncbo} \\ 
        A_{cbo}(t) &= \boldsymbol{A} \cdot (1 + \boldsymbol{A_{cbo-A}} \cdot e^{-t/\boldsymbol{\tau_{cbo}}} \cdot \cos(\omega_{cbo}(t) \cdot t + \boldsymbol{\phi_{cbo-A}})) \label{eq:Acbo} \\ 
        \phi_{cbo}(t) &= \boldsymbol{\phi_{0}} + \boldsymbol{A_{cbo-\phi}} \cdot e^{-t/\boldsymbol{\tau_{cbo}}} \cdot \cos(\omega_{cbo}(t) \cdot t + \boldsymbol{\phi_{cbo-\phi}}) \label{eq:Phicbo}
    \end{align}
In \equref{eq:Ncbo} the $\boldsymbol{N_{0}}$ term is left out since the ratio fit includes the $N_{cbo}(t)$ term but not $\boldsymbol{N_{0}}$, and in \equref{eq:Phicbo}, $\phi_{cbo}(t)$ has an additive phase instead of a multiplicative one since $\boldsymbol{\phi_{0}}$ is not an amplitude and can be equal to zero. Each of the terms then includes additional fit parameters in an extra amplitude and phase, as well as one shared CBO lifetime and frequency. As described in \secref{sec:MuonBeamMeasurements}, the default model for the CBO modulation is assumed as an exponentially decaying envelope. The CBO frequency, $\omega_{cbo}(t)$, was time-dependent for Run~1 as found in \secref{sec:MuonBeamMeasurements}. The function for the CBO frequency shown in \figref{fig:CBOFreqAmp} is given in the fit function as
    \begin{align} \label{eq:CBOfreqForm}
        \omega_{cbo}(t) = \boldsymbol{\omega_{cbo}} \cdot \Big(1 + \frac{Ae^{(-t/\tau_{A})}}{\omega_{0}t} + \frac{Be^{(-t/\tau_{B})}}{\omega_{0}t}\Big),
    \end{align}
where $\boldsymbol{\omega_{cbo}}$ is the free fit parameter, and the model parameters $\{\omega_{0}, A, \tau_{A}, B, \tau_{B}\}$ are fixed from the tracking analysis. These parameters for the various datasets and two tracker stations are given in \tabref{tab:CBOFrequencyParameters}. 



% \begin{landscape}
\begin{table}
\centering
\small
\setlength\tabcolsep{10pt}
\renewcommand{\arraystretch}{1.2}
\begin{tabular*}{1\linewidth}{@{\extracolsep{\fill}}lcccccc}
  \hline
    \multicolumn{7}{c}{\textbf{CBO Frequency Model Parameters}} \\
  \hline\hline
    Dataset & Tracker Station & $\omega_{0}$ (rad/\mus{}) & $A$ (rad) & $\tau_{A}$ (\mus{}) & $B$ (rad) & $\tau_{B}$ (\mus{}) \\
  \hline
    \multirow{2}{*}{60h} & 12 & 2.3389 & 2.9 & 81.8 & 5.12 & 7.7 \\
                         & 18 & 2.3387 & 2.82 & 81.1 & 5.08 & 8.2 \\
  \hline
    \multirow{2}{*}{HighKick} & 12 & 2.6145 & 3.27 & 52.8 & 6.96 & 6.6 \\
                              & 18 & 2.6137 & 3.23 & 46.2 & 6.61 & 6.8 \\
  \hline
    \multirow{2}{*}{9d} & 12 & 2.6106 & 2.86 & 72.8 & 5.50 & 8.5 \\
                        & 18 & 2.6110 & 2.89 & 79.2 & 5.44 & 9.2 \\
  % \hline
  %   \multirow{2}{*}{LowKick} & 12 &  &  &  &  &  \\
  %                            & 18 &  &  &  &  &  \\
  % \hline
  %   \multirow{2}{.07\textwidth}{SuperLowKick} & 12 &  &  &  &  &  \\
  %                                             & 18 &  &  &  &  &  \\
  \hline
    \multirow{2}{*}{Endgame} & 12 & 2.3377 & 7.43 & 95.1 & 4.71 & 9.0 \\
                             & 18 & 2.3379 & 7.44 & 95.2 & 4.90 & 9.2 \\                                                        
  \hline
\end{tabular*}
\caption[Dataset CBO frequency model parameters]{Fixed parameters in the CBO frequency model \cite{CBOFreqTrackingElog,JamesPersonalComm}. The larger values of the $A$ and $\tau_{A}$ parameters for the Endgame dataset are a consequence of the degradation of the quadrupole resistors over the course of Run~1.}
\label{tab:CBOFrequencyParameters}
\end{table}
% \end{landscape}


It should be noted that Equations~\ref{eq:Acbo} and \ref{eq:Phicbo} are not necessarily needed in order to get good fits to the data (whereas \equref{eq:Ncbo} always is). This is typically dataset or random seed dependent. While some datasets had certain parameters with large errors relative to their amplitudes, for this analysis all terms were included in all fits. Fits converged properly with appropriate tuning of the starting parameters, justifying their inclusion. When considering higher order CBO modifications to the fit function, the only term that was found to be necessary was the second order CBO modulation on the $\boldsymbol{N_{0}}$ term, $N_{0} \cdot N_{cbo}(t) \rightarrow N_{0} \cdot N_{cbo}(t) \cdot  N_{2cbo}(t)$, where
    \begin{align}
        N_{2cbo}(t) &= (1 + \boldsymbol{A_{2cbo-N}} \cdot e^{-2t/\boldsymbol{\tau_{cbo}}} \cdot \cos(\omega_{cbo}(t) \cdot t + \boldsymbol{\phi_{2cbo-N}})). \label{eq:N2cbo}
    \end{align}
This stands to reason as the $N_{cbo}(t)$ is the largest CBO effect. The form is assumed to be the same as the first order CBO terms, except the lifetime of the effect is half the CBO lifetime, $\boldsymbol{\tau_{cbo}}/2$. This is due to the fact that $N_{2cbo}(t)$ comes from the width of the oscillating beam, as opposed to the oscillating mean. Indeed as will be shown in \secref{sub:per_calorimeter_fits}, the inclusion of this term is necessary to get good fits to the per calorimeter data, where the CBO effect is stronger compared to the sum of the data from all calorimeters. 


% For this reason, and again because the $N_{2cbo}(t)$ term is fittable in the calorimeter sum data, this term is included in fits to each of the datasets.


Systematic studies relating to the choice of CBO envelope and choice of fixed parameters in the CBO frequency model are explored in \secref{sub:cboerror}. For future runs beyond Run~1, it may be necessary to include the higher order modifications to the $A_{cbo}(t)$ and $\phi_{cbo}(t)$ terms.



\subsection{VW term}
\label{sub:vw_term}

As mentioned at the end of \secref{sec:Histogramming}, the VW effect is time-randomized out of the data, such that $V(t) = 1$. This is done due to complications with the Ratio Method. In the 60h and Endgame datasets, the VW frequency was found to be nearly 10\wa, on a potential resonance. While to first order this even multiple frequency implies the VW effect should completely cancel out in the Ratio Method, \figref{fig:CancellationInRatioMethod}, the FR effect in combination with the VW leads to a modified envelope for the VW effect in the Ratio Method fits and inflated VW amplitudes \cite{VWinRatio}. See Figures~\ref{fig:VWresonance} and \ref{fig:JamesMC_VW_FR}.

\begin{figure}
    \centering
    \includegraphics[width=.7\textwidth]{AvwResonance_60h}
    \caption[VW amplitude resonance in the 60h dataset]{Fitted VW amplitude as a function of the choice of  offset from $T_{a}$ in units of thousands of ppm for the 60h dataset. The default time-shift lies at 0 on this plot, right on the resonance where the VW amplitude blows up. Only by time-shifting by a drastically different amount (which negatively affects R), can the resonance be avoided.}
    \label{fig:VWresonance}
\end{figure}


\begin{figure}
\centering
    \begin{subfigure}[t]{0.6\textwidth}
        \centering
        \includegraphics[width=\textwidth]{JamesMC_noFR}
        \caption{Without the FR effect included.}
    \end{subfigure}%

    \begin{subfigure}[t]{0.6\textwidth}
        \centering
        \includegraphics[width=\textwidth]{JamesMC_withFR}
        \caption{With the FR effect included.}
    \end{subfigure}
\caption[VW envelope in Ratio Method Toy MC data with and without FR effect]{Ratio data with and without the FR effect from a Toy MC simulation, with a VW effect with a frequency $\omega_{VW} = 10 \omega_{a}$. The \wa wiggle itself has been removed, and the lifetime of the VW was set to a large number. The top plot shows ratio data which is consistent with 0 after all effects have been removed and the VW has divided out. The bottom plot shows ratio data inconsistent with 0, with oscillations at the VW frequency, and an interesting beating structure. Note the different scales.}
\label{fig:JamesMC_VW_FR}
\end{figure}


For the 9d dataset which has a VW frequency that's nearly 9\wa and avoids said resonance (and by extension the HighKick), it was found that the Ratio Method flattened out the VW amplitudes as a function of calorimeter number leading to a systematically smaller VW amplitude in the calorimeter sum fit compared to in a T-Method fit. The simplest solution to remove both of these problems was to randomize out the VW effect entirely. \tabref{tab:A_change} gives the change in asymmetry and corresponding change in the statistical error on R due to this added time randomization for three of the Run~1 datasets. It was found that the added randomization increased the statistical error on R by a negligible amount for the Run~1 analysis. It was also found that the added level of time-randomization changed the mean value of R for many random seed fits to the data by a small amount, statistically consistent without the extra randomization \cite{VWinRatio}. Going forward for the future runs, it may be necessary to include the proper VW envelope in the fits using a functional form of the FR instead of randomizing out the effect.

\begin{table}
\centering
\small
\setlength\tabcolsep{10pt}
\renewcommand{\arraystretch}{1.2}
\begin{tabular*}{1\linewidth}{@{\extracolsep{\fill}}lcccc}
  \hline
    \multicolumn{5}{c}{\textbf{Change in Asymmetry due to VW Randomization}} \\
  \hline\hline
    Dataset & $A$ no randomization & $A$ with randomization & $\Delta A$ & $\Delta \sigma_{R}$ (ppb) \\
  \hline
    60h & $0.3697$ & $0.3637$ & $-0.0060$ & $22.7$ \\
    HighKick & $0.3707$ & $0.3632$ & $-0.0075$ & $29.3$ \\
    9d & $0.3714$ & $0.3639$ & $-0.0075$ & $18.1$ \\
    Endgame & $0.3747$ & $0.3686$ & $-0.0061$ & $10.7$ \\
  \hline
\end{tabular*}
\caption[Asymmetry values in Run~1 datasets with VW time randomization]{Asymmetry values in the the Run~1 datasets with and without the VW randomization, and the corresponding change in the statistical error on R. An energy cut of 1700 MeV was applied to the data.}
\label{tab:A_change}
\end{table}



The form for the VW as it is used in the T-Method fits is taken identically to the CBO terms, 
    \begin{align} \label{eq:VWterm}
        V(t) = 1 + \boldsymbol{A_{VW}} \cdot e^{-t/\boldsymbol{\tau_{VW}}} \cos(\omega_{VW}(t) \cdot t + \boldsymbol{\phi_{VW}}), 
    \end{align}
with an exponentially decaying envelope, and additional amplitude and phase parameters. The VW frequency $\omega_{VW}$ is given in \equref{eq:VWfreq}, where it is seen to be dependent on the cyclotron frequency and vertical betatron frequency. Using Equations~\ref{eq:tunes} and \ref{eq:CBOfreq}, the dependence on the CBO frequency is seen as
    \begin{equation}
    \begin{aligned}
        \omega_{VW}(t) &= 2\pi (f_{c} - 2f_{y_{BO}}), \\
                    % &= 2\pi \Big[f_{c} - 2f_{cbo}\sqrt{\frac{2f_{c}}{f_{cbo}}-1}\Big]
                    &= 2\pi \Big(f_{c} - 2f_{cbo}(t)\sqrt{2f_{c}/f_{cbo}(t)-1}\Big),
    \label{eq:VWfreqOne}
    \end{aligned}
    \end{equation}
where $f_{cbo}(t) = \omega_{cbo}(t)/2\pi$ is determined in the tracking analysis as described in \secref{sub:cboterms} and given by \equref{eq:CBOfreqForm}. While \equref{eq:VWfreqOne} is the theoretical frequency for the VW effect in the continuous quadrupole approximation, it was found in the tracking analysis that including an adjustment factor on the CBO frequency $f_{cbo} \rightarrow \kappa f_{cbo}$ resulted in better agreement with the directly measured VW frequency \cite{cbofrequency,verticalbetatron}. In the fitting function itself, the VW frequency is then taken as
    \begin{align} \label{eq:VWfreqKappa}
        \omega_{VW}(t) = 2\pi \Big(f_{c} - 2 \cdot \boldsymbol{\kappa_{VW}} \cdot f_{cbo}(t)\sqrt{2f_{c}/(\boldsymbol{\kappa_{VW}} \cdot f_{cbo}(t))-1}\Big),
    \end{align}
where now the VW frequency fit parameter is $\boldsymbol{\kappa_{VW}}$. This adjustment factor ends up being on the order of about a percent in the fits to the data.




\subsection{Lost muons}
\label{subsec:lostmuons}


Muons lost from the storage ring during the frequency analysis portion of each fill will distort the observed decay positron spectrum. These hits show up as a rise at low frequencies in the FFT of the fit residuals due to the slow nature of the effect, \figref{fig:FFT_fiveParameter}. These muon losses typically originate from those muons with large betatron amplitudes which hit material near the edge of the storage ring, or those muons which experience local field perturbations one too many times. In both cases the muons will lose energy and spiral inward out of the ring, a fraction of which will then pass through multiple calorimeters. Because lost muons are minimum-ionizing particles (MIPs), they are relatively easily identified by their small energy deposition signature in hit calorimeters, around 170 \MeV as shown in the left peak in \figref{fig:energyHist}. These lost muons typically have a flight time between adjacent calorimeters of $\Delta t_{12} = \SI{6.5}{ns}$ \cite{lostmuonspaper,lostmuonsDenverTalk}. The $\Delta t$ and energy deposition distributions are shown in \figref{fig:lostmuondistributions}. By looking for coincidences between three adjacent calorimeters, or triples, and then applying cuts and subtracting backgrounds, a pure sample of lost muons can be constructed\footnote{Using triples rather than doubles helps reduce the accidental background while keeping enough statistics.}. This lost muon spectrum $L(t)$ can then be implemented into the fit function in order to account for the positrons that would have been observed later in the fill in the absence of losses.

\begin{figure}
\centering
    \begin{subfigure}[]{0.48\textwidth}
        \centering
        \includegraphics[width=\textwidth]{triples_deltaT_Endgame}
        \caption{}
    \end{subfigure}% %you need this % here to add spacing between subfigures
    \begin{subfigure}[]{0.48\textwidth}
        \centering
        \includegraphics[width=\textwidth]{triples_Edep_Endgame}
        \caption{}
    \end{subfigure}
\caption[Lost muon $\Delta t$ and energy deposition distributions]{$\Delta t$ and energy deposition distributions for lost muons passing through adjacent calorimeters, where counts have been included from hits in both calos. A typical flight time is \ns{6.5} and energy deposition is 170 \MeV. Data are from the Endgame dataset.}
\label{fig:lostmuondistributions}
\end{figure}


\begin{table}
\centering
\setlength\tabcolsep{10pt}
\renewcommand{\arraystretch}{1.2}
\begin{tabular*}{1\linewidth}{@{\extracolsep{\fill}}lc}
  \hline
    \multicolumn{2}{c}{\textbf{Lost Muon Cuts}} \\
  \hline\hline
    Parameter & Value or Range \\
  \hline
    Cluster size & $\leq$ 3 crystals \\
    Cluster energy fraction & $\geq$ 0.8 in main crystal \\
    Time of flight between adjacent calorimeters & $\SI{5}{ns} \leq \Delta t_{12, 23} \leq \SI{7.5}{ns}$ \\
    Energy deposition & $\SI{100}{\MeV} \leq E_{1,2,3} \leq \SI{250}{\MeV}$ \\
    Time of flight between separated calorimeters & $\Delta t_{13} \leq \SI{14.4}{ns}$ \\
  \hline 
\end{tabular*}
\caption[Lost muon cuts]{Lost muon selection cuts. In a triple coincidence the subscripts of 1, 2, and 3 correspond to the three calorimeters hit clockwise around the ring.}
\label{tab:lostmuoncuts}
\end{table}



The cuts used for the lost muon selection are given in \tabref{tab:lostmuoncuts}. Triple coincidences are only included where every cluster consists of three or less crystals hit, with 80\% of the energy deposited in one crystal. $\Delta t$ and energy deposition ranges are taken as $\SI{5}{ns} \leq \Delta t_{12, 23} \leq \SI{7.5}{ns}$ and $\SI{100}{\MeV} \leq E_{1,2,3} \leq \SI{250}{\MeV}$, where these ranges come from inspection of \figref{fig:lostmuondistributions}. The \DT distribution as a function of time in-fill is shown in \figref{fig:deltaT12_AccSub}. By examining this distribution in the range $\SI{2}{ns} \leq \Delta t_{12} \leq \SI{4}{ns}$, and averaging the contained counts, an approximation for the accidental background can be determined and subtracted off the triples spectrum. The accidental background typically comes from either double coincidences and a real positron hit, or a particle shower induced by an incident positron which hits an adjacent calorimeter. 


% \begin{figure}
% \centering
%         \includegraphics[width=0.9\textwidth]{deltaT12_beforeAccSubtraction_Endgame}
%         \includegraphics[width=0.9\textwidth]{deltaT12_afterAccSubtraction_Endgame}
% \caption[Lost muon \DT distribution as a function of time in-fill]{\DT distribution as a function of time in-fill before (top) and after (bottom) accidental background subtraction. Note the log scale and the cahnge in colors at the far left of the bottom plot. Lost muons have a \DT distribution centered at \ns{6.5}. The accidental background can be seen as counts out at $\Delta t$'s far from the center of the distribution. Color striations in the core of the distribution correspond to CBO periods. There are two bands of hits that do not fall off as severely with time as the lost muons do. The band contained between 7 and \ns{8} corresponds to deuterons, while the band contained between 6 and \ns{7} corresponds to protons. Data are from the Endgame dataset.}
% \label{fig:deltaT12_AccSub}
% \end{figure}

\begin{figure}
\centering
        \includegraphics[width=1\textwidth]{deltaT12_beforeAccSubtraction_Endgame}
\caption[Lost muon \DT distribution as a function of time in-fill]{\DT distribution as a function of time in-fill before any cuts. Note the log color scale. Lost muons have a \DT distribution centered at \ns{6.5}. The accidental background can be seen as counts out at $\Delta t$'s far from the center of the distribution. Color striations in the core of the distribution correspond to CBO periods. There are two bands of hits that do not fall off as severely with time as the lost muons do. The band contained mostly between 7 and \ns{8} corresponds to deuterons, while the band contained mostly between 6 and \ns{7} corresponds to protons. Data are from the Endgame dataset.}
\label{fig:deltaT12_AccSub}
\end{figure}


Also shown in \figref{fig:deltaT12_AccSub} are two bands of stable beam contaminants corresponding to stored deuterons and protons. These particles have different times of flights between calorimeters due to their larger masses. By looking at the $\Delta t_{13}$ distribution for times greater than \mus{300} so that most muons have already decayed, the deuteron population is easily isolated, \figref{fig:deuteronPop}. While the deuteron population is mostly removed by the \DT cut, an additional cut of $\Delta t_{13} \leq \SI{14.4}{ns}$ helps remove any remaining deuteron contamination. The proton population, due to its similarity to the real lost muon population, is harder to remove. The simplest solution is to simply cut on the negative side of the \DT or $\Delta t_{13}$ distributions. See \secref{sub:lostmuonserror} for the results using this additional cut. It was found that the proton contamination makes almost no difference to the fitted value of R. The default choice then is to use the previously specified cut ranges in order to increase the amount of statistics in the lost muons distribution with which to fit. A study into the exact rate of these beam contaminants is included in \refref{lostmuonsKevin}.


\begin{figure}
    \centering
    \includegraphics[width=.7\textwidth]{deuteron_Population_Endgame}
    \caption[Deuteron population at late times]{$\Delta t_{13}$ distribution as a function of energy for times greater than \mus{300}. The lost muons can be seen centered at 170 \MeV and $\Delta t_{13} \approx \SI{12.5}{ns}$, while the deuterons can be seen at $\Delta t_{13} \geq \SI{14.4}{ns}$. While the deuterons have a preferentially larger energy deposition, they can be seen to extend to low energies, making cutting on energy unrealistic. Though not easily separated by eye, the stored protons are contained within the upper right portion of the lost muons. Data are from the Endgame dataset.}
    \label{fig:deuteronPop}
\end{figure}


The last background is the quadruples spectrum. Due to how the triple coincidences are constructed, real quadruples will be counted as two separate triples. While the quadruples spectrum can be used instead of the triples spectrum for a purer sample of lost muons, the statistics are much reduced, and similarly for higher order coincidences. The quadruples spectrum is constructed in the same was as the triples with the same cut ranges. The quadruple background is removed by subtracting off those triples which originated from quadruple coincidences.


\begin{figure}
    \centering
    \includegraphics[width=.8\textwidth]{deltaT12_timeInFill_finalCuts_Endgame}
    \caption[Final \DT distribution for selected lost muons]{Final \DT distribution for selected lost muons as a function of time in-fill. Data are from the Endgame dataset.}
    \label{fig:finalDT12Dist}
\end{figure}

\begin{figure}
    \centering
    \includegraphics[width=0.9\textwidth]{Triples_vs_all_Endgame}
    \caption[Lost muon triples spectrum compared to quadruples and accidental background]{Lost muon triples spectrum $L(t)$ as a function of time in-fill, after all cuts and background subtractions. Also shown are the quadruples and accidental background distributions, which can be seen to be much smaller than the triples. The shape of the triple and quadruple spectra can be seen to be nearly the same. The shape of the triples spectrum comes from beam dynamics (CBO) and lost muon acceptance effects. Data are from the Endgame dataset.}
    \label{fig:triples}
\end{figure}


\figref{fig:finalDT12Dist} shows the final \DT distribution with cuts as a function of time in-fill for selected lost muons. The final triple losses spectrum $L(t)$ is shown in \figref{fig:triples}. Once we have the lost muon distribution we need to include it in the fit function in order to account for the changing number of hits over the course of the fill. The true lost muon rate will be given by $L(t)/\epsilon$, where $\epsilon$ is the loss detection efficiency. The change in the number of muons within the storage ring can be written as 
    \begin{align} 
        dN = -\frac{N}{\tau} dt - \frac{L(t)}{\epsilon} dt, 
    \end{align}
where the solution can be determined by inspection as
    \begin{align} 
        N(t) = N_{0} \cdot e^{-t/\tau} \cdot (1 - \frac{1}{\epsilon N_{0}} \int_{t_{0}}^{t} L(t')e^{(t'/\tau)} dt').
    \end{align}
The parameter $\tau$ is the same muon lifetime as in the T-Method fit function, except here it is set as the default value of \mus{64.44}\footnote{The fitted \wa frequency is largely insensitive to this parameter, and especially so in the Ratio Method fits, so this is acceptable. If necessary, the fitting procedure can be iterated.}. The value for $t_{0}$ can be taken as any time at or before the start of the fitting range, as it simply changes the scale of $N_{0}$. The modification $\Lambda(t)$ as listed in \equref{eq:TmethodFunction} is then taken as
    \begin{align} \label{eq:lambdalosses}
        \Lambda(t) = 1 - \boldsymbol{\kappa_{loss}} \int_{t_{0}}^{t} L(t')e^{(t'/\tau)} dt'
    \end{align}
where $\boldsymbol{\kappa_{loss}} = 1/\epsilon N_{0}$ is taken as the fit parameter\footnote{By construction $\kappa_{loss}$ is a very small parameter, $\mathcal{O}(10^{-10})$. This factor is absorbed into the parameter in such that the fit parameter is $\mathcal{O}(1)$.}.

It should be noted that the Ratio Method is largely insensitive to the slow lost muons effect which divides out. No rise appears in the FFT of the ratio fit residuals, \figref{fig:fft_threeParamRatio}, and when letting $\boldsymbol{\kappa_{loss}}$ float, the fit does not converge. It was found however that $\boldsymbol{R}$ changes on the order of tens of ppb when the lost muon term is included with $\boldsymbol{\kappa_{loss}}$ fixed to the value determined from a T-Method fit, so by default it is included. See \secref{sub:lostmuonserror} for more discussion on this.


\subsection{Fit procedures and parameters}

\chisq fits are done to the pileup corrected positron time spectra and ratio data in \texttt{ROOT} using the standard \texttt{TH1F} and \texttt{TGraph} fit methods with a strategy level of two. Fits are performed in stages where groups of associated parameters are freed, fit, and then fixed before fitting the next set of parameters. In the final fit all parameters are free. Each of the four Run~1 precession frequency analysis datasets are fit with 14 parameters. 13 parameters are free in fits to the 60h, 9d, and Endgame datasets, with the \K parameter determined and fixed from a T-Method fit. In the HighKick dataset $\tau_{cbo}$ is also fixed from a T-Method fit as the lifetime is relatively short and the Ratio Method can't successfully fit it, resulting in 12 free fit parameters. In the T-Method fits there are two extra free fit parameters, those being the $N_{0}$ and $\tau$ terms which are divided out of the Ratio Method fits.

Fits to calorimeter sum spectra are done over the range 30.2--\mus{650}, corresponding to 4155 bins\footnote{The fit range is not defined on exact bin edges, and those bins where the fit begins and ends are included in the fit.}. The choice of fit start time was made to allow for the muon beam to stabilize in the storage region after the scraping procedure. In addition the start time was chosen to lie directly on a \gmtwo zero crossing, which from E821 experience was shown to reduce some systematic errors. The choice of fit end time was made to be well before the limit at which the bin variance become non-Gaussian. Individual calorimeter fits were performed out to \mus{400} considering this fact. \tabref{tab:fitprocedureparameters} gives the various fit procedure parameters.

% The choice of fit end time was made to be just before the quadrupole storage field turned off, in order for the fill time to fit within the timing structure of the experimental beam. 

As a reminder $R$ is blinded at the hardware and software levels \cite{ClockManual,SoftwareBlinding}. The software blinding string used for the 60h dataset was different than that used when fitting the HighKick, 9d, and Endgame datasets, each of which used the same blinding string. This was done in order to perform a software-level relative unblinding exercise between different analyzers with the 60h dataset in order to determine if there were any obvious problems in the analyses \cite{BU60hReport,60hUnblinding}. Therefore in the following results, $R$ values between different datasets are comparable between the datasets except for the 60h, barring any differences due to field conditions which are not discussed in this dissertation.


\begin{table}
\centering
\setlength\tabcolsep{10pt}
\renewcommand{\arraystretch}{1.2}{}
\begin{tabular*}{.8\linewidth}{@{\extracolsep{\fill}}lc}
  \hline
    \multicolumn{2}{c}{\textbf{Fit Procedure Parameters}} \\
  \hline\hline
    Parameter & Value \\
  \hline
    Fit strategy level & 2 \\
    Fit start time & \mus{30.2} \\
    Fit end time (calorimeter sum) & \mus{650} \\
    Fit end time (single calorimeters) & \mus{400} \\
    Bins in fit (calorimeter sum) & 4155 \\
    % Number of fit parameters & 14 \\
    Number of free fit parameters (60h, 9d, Endgame) & 13 \\
    Number of free fit parameters (HighKick) & 12 \\
  \hline 
\end{tabular*}
\caption[Fit procedure parameters]{Various parameters used in the fit procedure.}
\label{tab:fitprocedureparameters}
\end{table}


The names of the specific SAM (Sequential Access via Metadata) datasets that were analyzed for this dissertation are given in \tabref{tab:SAMNames}. SAM is a data handling system used at Fermilab to store and retrieve files along with associated metadata. The specific DQC cuts, included gain corrections, processed runs, production software versions, etc. can all be recovered by examining the associated SAM metadata.



\begin{table}
\centering
\setlength\tabcolsep{10pt}
\renewcommand{\arraystretch}{1.2}{}
\begin{tabular*}{.8\linewidth}{@{\extracolsep{\fill}}lc}
  \hline
    \multicolumn{2}{c}{\textbf{SAM Dataset Names}} \\
  \hline\hline
    Dataset & Name \\
  \hline
    60h & gm2pro\underline{{ }}daq\underline{{ }}full\underline{{ }}run1\underline{{ }}60h\underline{{ }}5039A\underline{{ }}goldList \\ 
    HighKick & gm2pro\underline{{ }}daq\underline{{ }}full\underline{{ }}run1\underline{{ }}HighKick\underline{{ }}5040A\underline{{ }}goldList \\
    9d & gm2pro\underline{{ }}daq\underline{{ }}full\underline{{ }}run1\underline{{ }}9d\underline{{ }}5039A\underline{{ }}goldList \\
    Endgame & gm2pro\underline{{ }}daq\underline{{ }}full\underline{{ }}run1\underline{{ }}EndGame\underline{{ }}5040A\underline{{ }}goldList \\
  \hline 
\end{tabular*}
\caption[SAM dataset names]{The SAM dataset names of the Run~1 precession frequency analysis datasets.}
\label{tab:SAMNames}
\end{table}




\input{Body/Wa_FitResults}
\clearpage
\input{Body/Wa_Systematics}

